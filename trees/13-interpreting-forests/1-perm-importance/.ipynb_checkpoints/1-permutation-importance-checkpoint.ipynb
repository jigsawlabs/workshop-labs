{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous lessons, we've learned about how to tune our random forest model.  While we have tuned models that are perhaps good at predicting a specific outcome, we do not know how our random forest is using our features to make these predictions.  This is significant.  We want to use our models to not only predict the future, but also to tell us what factors are significant so that we can potentially change the future.  \n",
    "\n",
    "There are two components to this.  First, is determining which of our features are most important.  Second is to determine the expected change in our target value as we change the value of a feature.  \n",
    "\n",
    "In this lesson, we'll focus on finding our most influential features, and removing less important features from our model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading our data and training our `RandomForestRegressor`.  We'll work with our preprocessed AirBnb data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First we load up our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_feather('./bnb_train.feather')\n",
    "df_X_train = df_train.drop(columns = ['price'])\n",
    "y_train = df_train.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> And now our validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_feather('./bnb_val.feather')\n",
    "df_X_val = df_val.drop(columns = ['price'])\n",
    "y_val = df_val.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next we train our model using the hyperparameters that we previously discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7572817041357578"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=40, max_features='log2')\n",
    "rfr.fit(df_X_train, y_train)\n",
    "rfr.score(df_X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve a `.75` accuracy score on our validation set.  It's time to see what factors influence that model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the feature importances, we could use the `sklearn` library's `rfr.feature_importances_` function.  However, a more accurate technique comes from the `eli5` library's `PermutationImportance` transformer.  Let's see the `PermutationImportance` in action, and then we'll see how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have not already, we should run `pip install eli5` in the terminal.  Then we use the `PermutationImportance` transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5.sklearn import PermutationImportance\n",
    "perm = PermutationImportance(rfr).fit(df_X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `eli5` is using a similar interface to sklearn.  It first initializes the transformer with our `RandomForestRegressor`, `rfr`, and then fits the regressor on our validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can the features in order of importance with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calculated_host_listings_count</td>\n",
       "      <td>0.076291</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>license_is_na</td>\n",
       "      <td>0.073342</td>\n",
       "      <td>0.010245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>property_type_other</td>\n",
       "      <td>0.069124</td>\n",
       "      <td>0.006424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>host_verifications_['email', 'phone']</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.009262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>host_total_listings_count</td>\n",
       "      <td>0.066563</td>\n",
       "      <td>0.009125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>host_neighbourhood_is_na</td>\n",
       "      <td>0.064419</td>\n",
       "      <td>0.007286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neighbourhood_Wilmersdorf</td>\n",
       "      <td>0.051356</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>host_listings_count</td>\n",
       "      <td>0.049906</td>\n",
       "      <td>0.002391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>index</td>\n",
       "      <td>0.037970</td>\n",
       "      <td>0.002161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>availability_60</td>\n",
       "      <td>0.033209</td>\n",
       "      <td>0.004940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 feature    weight       std\n",
       "0         calculated_host_listings_count  0.076291  0.000196\n",
       "1                          license_is_na  0.073342  0.010245\n",
       "2                    property_type_other  0.069124  0.006424\n",
       "3  host_verifications_['email', 'phone']  0.068592  0.009262\n",
       "4              host_total_listings_count  0.066563  0.009125\n",
       "5               host_neighbourhood_is_na  0.064419  0.007286\n",
       "6              neighbourhood_Wilmersdorf  0.051356  0.000071\n",
       "7                    host_listings_count  0.049906  0.002391\n",
       "8                                  index  0.037970  0.002161\n",
       "9                        availability_60  0.033209  0.004940"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "eli5.explain_weights_df(perm, feature_names = df_X_train.columns.to_list(), top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so above we can see that according to `PermutationImportance`, that the most important features are `host_listings_count` and `availability_60`.  Our features are ordered by their `weight`.  Now it's time to learn what `weight` means, and how permutation importance works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining Permutation Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand permutation importance, let's start with perhaps the ideal way to determine the most important features.  The ideal way to determine if our feature is important, is simply to train our model with all of the features and see the accuracy of the model.  And then to see if a feature is important, we can simply remove the feature, retrain our model, and see how much worse the model performs.  If the model performs a lot worse, our feature was important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "model_all_features = RandomForestRegressor()\n",
    "model_all_features.fit(df_X_train, y_train).score(df_X_val, y_val)\n",
    "\n",
    "scores = []\n",
    "for column in X_train.columns:\n",
    "    X_train_minus_one = df_X_train.drop(columns = [column])\n",
    "    X_valid_minus_one = df_X_valid.drop(columns = [column])\n",
    "    model_all_features.fit(X_train_minus_one, y_valid)\n",
    "    score = model_all_features.score(X_valid_minus_one, y_valid)\n",
    "    scores.append(score)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the only issue with this ideal approach is that retraining the model for each feature can take a lot of time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to save time, we use permutation importance to do the next best thing.  With permutation importance, instead of retraining a model once for each feature, we only train our model one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7387637461679417"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all_features = RandomForestRegressor(n_estimators=40, max_features='log2')\n",
    "model_all_features.fit(df_X_train, y_train).score(df_X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, once our model is trained, we see how important a feature is by replacing the feature's real data with random data. And the random data we use for that feature is simply the original data shuffled.  For example, let's say that we want to determine the feature importance of `host_sinceDayofyear`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the original feature data and related target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    1\n",
       " 1    1\n",
       " 2    4\n",
       " 3    1\n",
       " 4    1\n",
       " Name: calculated_host_listings_count, dtype: int64, 0    30.0\n",
       " 1    45.0\n",
       " 2    39.0\n",
       " 3    60.0\n",
       " 4    35.0\n",
       " Name: price, dtype: float64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_val['calculated_host_listings_count'].head(), y_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of scoring the model with the original `host_sinceDayofyear`, we shuffle that feature data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4370    1\n",
       " 881     1\n",
       " 3214    1\n",
       " 3782    1\n",
       " 4442    1\n",
       " Name: calculated_host_listings_count, dtype: int64, 0    30.0\n",
       " 1    45.0\n",
       " 2    39.0\n",
       " 3    60.0\n",
       " 4    35.0\n",
       " Name: price, dtype: float64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_host_since = df_X_val['calculated_host_listings_count'].sample(frac=1, random_state = 1)\n",
    "shuffled_host_since.head(), y_val_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then score the model with that one feature's data shuffled.  Which is close to if we removed that data entirely, and see how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4370\n",
       "1     881\n",
       "2    3214\n",
       "3    3782\n",
       "4    4442\n",
       "Name: calculated_host_listings_count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_X_val = df_X_val.copy()\n",
    "host_listings_permute = permuted_X_val['calculated_host_listings_count'].sample(frac=1, random_state=1).reset_index()\n",
    "permuted_X_val['calculated_host_listings_count'] = host_listings_permute\n",
    "permuted_X_val['calculated_host_listings_count'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26978065177587496"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all_features.score(permuted_X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our score decreased drastically from `.73` to `.269`.  With permutation importance library, it performs this operation many times for each feature to see the average decrease in score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can better understand our permutation importances function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calculated_host_listings_count</td>\n",
       "      <td>0.076291</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>license_is_na</td>\n",
       "      <td>0.073342</td>\n",
       "      <td>0.010245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>property_type_other</td>\n",
       "      <td>0.069124</td>\n",
       "      <td>0.006424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>host_verifications_['email', 'phone']</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.009262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>host_total_listings_count</td>\n",
       "      <td>0.066563</td>\n",
       "      <td>0.009125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 feature    weight       std\n",
       "0         calculated_host_listings_count  0.076291  0.000196\n",
       "1                          license_is_na  0.073342  0.010245\n",
       "2                    property_type_other  0.069124  0.006424\n",
       "3  host_verifications_['email', 'phone']  0.068592  0.009262\n",
       "4              host_total_listings_count  0.066563  0.009125"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "feat_imp_df = eli5.explain_weights_df(perm, feature_names=df_X_train.columns.to_list())\n",
    "feat_imp_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we learned how to view the importances of a random forest with the `PermutationImportance` transformer from `eli5`.  We saw that the library approximates the decrease in the model's accuracy if the feature were removed, by shuffling each feature and calculating the decrease in accuaracy.  The library does this many times to calculate the mean and standard deviation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
