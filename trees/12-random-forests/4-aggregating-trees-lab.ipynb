{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating Trees Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll see the benefits of aggregating trees in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, let's work with the diabetes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by loading the diabetes dataset from sklearn.  Assign `X` to our feature variables and `y` to the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "dataset = load_diabetes()\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# (442, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n",
    "# (442,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split our data into training, test and validation sets.\n",
    "\n",
    "Perform this by:\n",
    "1. Splitting the data into training and test sets\n",
    "2. Splitting the training set into training and validation sets\n",
    "\n",
    "* Use the `random_state=1` and `test_size=0.2` for both splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07453279,  0.05068012, -0.00943939,  0.01498661, -0.03734373,\n",
       "        -0.02166853, -0.01394774, -0.00259226, -0.03324879,  0.01134862]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1]\n",
    "# array([[-0.07453279,  0.05068012, -0.00943939,  0.01498661, -0.03734373,\n",
    "#         -0.02166853, -0.01394774, -0.00259226, -0.03324879,  0.01134862]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01991321,  0.05068012,  0.01427248,  0.0631868 ,  0.01494247,\n",
       "         0.02029337, -0.04708248,  0.03430886,  0.04666077,  0.09004865]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[:1]\n",
    "# array([[ 0.01991321,  0.05068012,  0.01427248,  0.0631868 ,  0.01494247,\n",
    "#         0.02029337, -0.04708248,  0.03430886,  0.04666077,  0.09004865]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04170844, -0.04464164, -0.03207344, -0.06190417,  0.07961226,\n",
       "         0.05098192,  0.05600338, -0.00997249,  0.04506617, -0.05906719]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]\n",
    "\n",
    "#array([[ 0.04170844, -0.04464164, -0.03207344, -0.06190417,  0.07961226,\n",
    "#         0.05098192,  0.05600338, -0.00997249,  0.04506617, -0.05906719]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll begin aggregating our trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by fitting multiple decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23996310700798584"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a list of five trees.  Fit each tree on the entire training set.  Set the random state on the `DecistionTreeRegressor` to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_trees = []\n",
    "for idx in range(0, 5):\n",
    "    dtr = DecisionTreeRegressor(random_state=1)\n",
    "    dtr.fit(X_train, y_train)\n",
    "    fitted_trees.append(dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11528633202604144,\n",
       " 0.11528633202604144,\n",
       " 0.11528633202604144,\n",
       " 0.11528633202604144,\n",
       " 0.11528633202604144]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tree.score(X_val, y_val) for tree in fitted_trees]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each tree performs the same, because each tree is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"304pt\" height=\"244pt\"\n",
       " viewBox=\"0.00 0.00 304.00 244.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 240)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-240 300,-240 300,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"201.2133,-236 94.7867,-236 94.7867,-172 201.2133,-172 201.2133,-236\"/>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">s5 &lt;= 0.022</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 5942.067</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 282</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 150.337</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"138.9473,-136 33.0527,-136 33.0527,-72 138.9473,-72 138.9473,-136\"/>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bmi &lt;= 0.006</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 3929.642</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 187</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 119.77</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M128.0415,-171.8089C122.6763,-163.1553 116.8035,-153.683 111.1937,-144.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"114.1652,-142.7855 105.9211,-136.1308 108.2159,-146.4741 114.1652,-142.7855\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.2118\" y=\"-156.2701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 356 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>356</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"263.2133,-136 156.7867,-136 156.7867,-72 263.2133,-72 263.2133,-136\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bp &lt;= 0.058</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 4443.976</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 95</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 210.505</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;356 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;356</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M167.9585,-171.8089C173.3237,-163.1553 179.1965,-153.683 184.8063,-144.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.7841,-146.4741 190.0789,-136.1308 181.8348,-142.7855 187.7841,-146.4741\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.7882\" y=\"-156.2701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"54,-36 0,-36 0,0 54,0 54,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M64.0306,-71.9768C57.8384,-62.9509 51.1718,-53.2335 45.2249,-44.5651\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"48.1053,-42.5768 39.562,-36.3108 42.3331,-46.5368 48.1053,-42.5768\"/>\n",
       "</g>\n",
       "<!-- 263 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>263</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"126,-36 72,-36 72,0 126,0 126,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;263 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;263</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M90.8407,-71.9768C92.1198,-63.515 93.4908,-54.4455 94.7369,-46.2023\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.198,-46.7216 96.2321,-36.3108 91.2767,-45.6753 98.198,-46.7216\"/>\n",
       "</g>\n",
       "<!-- 357 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>357</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"224,-36 170,-36 170,0 224,0 224,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 356&#45;&gt;357 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>356&#45;&gt;357</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M205.1593,-71.9768C203.8802,-63.515 202.5092,-54.4455 201.2631,-46.2023\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.7233,-45.6753 199.7679,-36.3108 197.802,-46.7216 204.7233,-45.6753\"/>\n",
       "</g>\n",
       "<!-- 492 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>492</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"296,-36 242,-36 242,0 296,0 296,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 356&#45;&gt;492 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>356&#45;&gt;492</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M231.9694,-71.9768C238.1616,-62.9509 244.8282,-53.2335 250.7751,-44.5651\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"253.6669,-46.5368 256.438,-36.3108 247.8947,-42.5768 253.6669,-46.5368\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a169a0860>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from IPython.display import SVG, display\n",
    "from graphviz import Source \n",
    "\n",
    "\n",
    "graph_1 = Source(tree.export_graphviz(fitted_trees[0], out_file=None,\n",
    "                                feature_names=dataset['feature_names'], max_depth = 1))\n",
    "\n",
    "graph_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"304pt\" height=\"244pt\"\n",
       " viewBox=\"0.00 0.00 304.00 244.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 240)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-240 300,-240 300,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"201.2133,-236 94.7867,-236 94.7867,-172 201.2133,-172 201.2133,-236\"/>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">s5 &lt;= 0.022</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 5942.067</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 282</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 150.337</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"138.9473,-136 33.0527,-136 33.0527,-72 138.9473,-72 138.9473,-136\"/>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bmi &lt;= 0.006</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 3929.642</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 187</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 119.77</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M128.0415,-171.8089C122.6763,-163.1553 116.8035,-153.683 111.1937,-144.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"114.1652,-142.7855 105.9211,-136.1308 108.2159,-146.4741 114.1652,-142.7855\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.2118\" y=\"-156.2701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 356 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>356</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"263.2133,-136 156.7867,-136 156.7867,-72 263.2133,-72 263.2133,-136\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bp &lt;= 0.058</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 4443.976</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 95</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 210.505</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;356 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;356</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M167.9585,-171.8089C173.3237,-163.1553 179.1965,-153.683 184.8063,-144.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.7841,-146.4741 190.0789,-136.1308 181.8348,-142.7855 187.7841,-146.4741\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.7882\" y=\"-156.2701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"54,-36 0,-36 0,0 54,0 54,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M64.0306,-71.9768C57.8384,-62.9509 51.1718,-53.2335 45.2249,-44.5651\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"48.1053,-42.5768 39.562,-36.3108 42.3331,-46.5368 48.1053,-42.5768\"/>\n",
       "</g>\n",
       "<!-- 263 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>263</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"126,-36 72,-36 72,0 126,0 126,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;263 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;263</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M90.8407,-71.9768C92.1198,-63.515 93.4908,-54.4455 94.7369,-46.2023\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.198,-46.7216 96.2321,-36.3108 91.2767,-45.6753 98.198,-46.7216\"/>\n",
       "</g>\n",
       "<!-- 357 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>357</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"224,-36 170,-36 170,0 224,0 224,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 356&#45;&gt;357 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>356&#45;&gt;357</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M205.1593,-71.9768C203.8802,-63.515 202.5092,-54.4455 201.2631,-46.2023\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.7233,-45.6753 199.7679,-36.3108 197.802,-46.7216 204.7233,-45.6753\"/>\n",
       "</g>\n",
       "<!-- 492 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>492</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"296,-36 242,-36 242,0 296,0 296,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 356&#45;&gt;492 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>356&#45;&gt;492</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M231.9694,-71.9768C238.1616,-62.9509 244.8282,-53.2335 250.7751,-44.5651\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"253.6669,-46.5368 256.438,-36.3108 247.8947,-42.5768 253.6669,-46.5368\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a16996f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from IPython.display import SVG, display\n",
    "from graphviz import Source \n",
    "\n",
    "\n",
    "graph_1 = Source(tree.export_graphviz(fitted_trees[1], out_file=None,\n",
    "                                feature_names=dataset['feature_names'], max_depth = 1))\n",
    "\n",
    "graph_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Subsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, next, let's use subsampling to get a different set of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With numpy we cannot directly subsample from the array.  But we can subsample from our training data by first selecting a set of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 10)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(.8*len(X_train))\n",
    "# 225\n",
    "np.random.seed(1)\n",
    "\n",
    "selected_idx = np.random.choice(len(X_train), 225)\n",
    "selected_idx[:3]\n",
    "\n",
    "# array([ 37, 235,  72])\n",
    "selected_X_train = X_train[selected_idx]\n",
    "selected_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the above code randomly selects eighty percent of the data.  Use this code to create ten additional trees, each trained on a random subset of 80 percent of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "subsample_trees = []\n",
    "for idx in range(0, 10):\n",
    "    selected_idx = np.random.choice(len(X_train), int(.8*len(X_train)))\n",
    "    selected_X_train = X_train[selected_idx]\n",
    "    selected_y_train = y_train[selected_idx]\n",
    "    dtr = DecisionTreeRegressor(random_state=1)\n",
    "    dtr.fit(selected_X_train, selected_y_train)\n",
    "    subsample_trees.append(dtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see a range of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.15968197330373535,\n",
       " 0.06229134651379642,\n",
       " -0.13175497298283,\n",
       " -0.07123695687619724,\n",
       " -0.19923387846021834,\n",
       " 0.057423115682577075,\n",
       " -0.17269466428515434,\n",
       " -0.08764006211264676,\n",
       " -0.1470755171909568,\n",
       " -0.005519134450968632]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_subsample_scores = [tree.score(X_val, y_val) for tree in subsample_trees]\n",
    "tree_subsample_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, individually, our trees don't perform any better than they did originally.  In many cases, the trees perform worse.  But the key component of a random forest is that our trees are different.  And that aggregating these differences will produce a more accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's use our first tree to make predictions on our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tree = subsample_trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = first_tree.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([264.,  48., 265., 235.,  90.,  48.,  53., 180., 171., 245., 150.,\n",
       "       230., 200.,  48., 317., 259.,  70., 163., 252., 163.,  54., 124.,\n",
       "       184.,  99., 163., 259., 116., 248., 206.,  49.,  92., 230., 293.,\n",
       "       275., 259., 265., 120., 281., 151., 180., 137.,  70.,  88.,  47.,\n",
       "       317., 281., 118., 257., 200., 168.,  69., 245., 144., 293., 263.,\n",
       "        99.,  65., 283.,  65., 274., 116.,  92., 142., 183., 151., 171.,\n",
       "       192.,  48.,  47., 163., 121.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here, we see the predictions that our tree makes for each observation.  \n",
    "\n",
    "Now for a random forest of three trees, we should have three trees make predictions, and then get the mean prediction for each observation across these trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Have each tree make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now let's first create a matrix where each row is a set of predictions for each tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use `vstack` along with list comprehension, to place each set of tree predictions into a separate row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tree_predictions = np.vstack([ tree.predict(X_val) for tree in subsample_trees])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a matrix where each row is a separate set of predictions.  The next step is to begin to aggregate these predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Aggregate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tree prediction matrix has a separate row for each set of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[268.,  48., 221., 197.,  63.,  48.,  61., 233., 131., 248., 257.,\n",
       "        111.,  99.,  47., 128., 175., 270., 210., 143., 237.,  72., 104.,\n",
       "        197., 101., 221., 175., 160., 185., 206., 116.,  84.,  75., 248.,\n",
       "        175.,  95., 232., 134.,  70.,  73., 259.,  45., 198.,  83.,  71.,\n",
       "        128., 232.,  72., 110., 150.,  73., 206., 185.,  44., 248., 235.,\n",
       "        143.,  53., 122.,  86.,  70., 116., 107., 113.,  71., 151., 134.,\n",
       "        192.,  65.,  48.,  84., 197.],\n",
       "       [150.,  77., 221., 202., 158., 153.,  63., 281., 259., 118., 295.,\n",
       "         59.,  65.,  64., 150., 140., 246., 277.,  67.,  70., 141.,  72.,\n",
       "         96.,  65., 220., 277.,  87., 161., 146., 143.,  74.,  64., 202.,\n",
       "        277., 103., 259., 141., 281., 197., 279., 101., 236.,  49., 101.,\n",
       "        192., 265., 118.,  70.,  87., 190., 249., 249., 153., 202., 220.,\n",
       "         61., 129.,  67.,  87., 244., 104., 131., 145.,  54., 225.,  83.,\n",
       "        128.,  42.,  52.,  70., 202.]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_predictions[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to take the mean prediction for each observation, across all of our rows.  If we just use `np.mean` numpy will calculate the mean score across all of our predictions.  But this isn't what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155.1014084507042"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tree_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we want the mean prediction for each observation.  Or the mean across our rows.  To do so, use `np.mean` with `axis` set to `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_predictions = np.mean(tree_predictions, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([243.8,  77. , 143.1, 174.7,  91.9,  65.3,  77.3, 224. , 179. ,\n",
       "       153.4, 239.5,  94.9,  94.9,  78.8, 249.5, 137.6, 244.8, 159.8,\n",
       "       235. , 210.5,  88.8, 105.4, 139.3,  91.5, 213.6, 179.8, 112.4,\n",
       "       162.5, 178.2,  88. , 128.5, 117.6, 221.8, 206.2, 125.9, 239.4,\n",
       "       176.6, 235.6, 159.9, 262.1, 112.4, 214.1,  90.5,  91.3, 228.5,\n",
       "       249.6, 102.4, 214.6, 153.1, 140.6, 106.2, 139.6, 107.1, 224.6,\n",
       "       266.7,  88.9,  58.3, 231.2, 134.5, 254.1,  74.9, 189.5, 137.6,\n",
       "       105.8, 139.4, 142.3, 162.6, 101.4,  72.8, 167. , 102.7])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71,)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we still have a prediction for each of our datapoints, but now they are mean of the predictions of our trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how this performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate the $r^2$ for our combined trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3868932963421975"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_val, aggregated_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our score dramatically increased by aggregating the trees.  In fact, we performed better than with any individual tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.15968197330373535,\n",
       " 0.06229134651379642,\n",
       " -0.13175497298283,\n",
       " -0.07123695687619724,\n",
       " -0.19923387846021834,\n",
       " 0.057423115682577075,\n",
       " -0.17269466428515434,\n",
       " -0.08764006211264676,\n",
       " -0.1470755171909568,\n",
       " -0.005519134450968632]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_subsample_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, finally, we'll provide the code to show how our predictions improve as we add each additional estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_scores = [r2_score(y_val, np.mean(tree_predictions[:i + 1], axis = 0)) for i in range(0, len(subsample_trees)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "markers",
         "name": "data",
         "text": [],
         "type": "scatter",
         "uid": "065d1b96-de97-48a3-8023-e0272c44951a",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.24923843719791383,
          0.33082082917562416,
          0.4338864581119427,
          0.453339481417917,
          0.46214081786104744,
          0.3998070734028383,
          0.40191055317088786,
          0.41359458038845254,
          0.42443502503868535,
          0.42552761574430875
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "xaxis": {
         "autorange": true,
         "range": [
          0.4073387694588585,
          10.592661230541141
         ],
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          0.233643676830869,
          0.47773557822809226
         ],
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"5a179071-4e22-4a84-aa4e-dbafcaffa391\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"5a179071-4e22-4a84-aa4e-dbafcaffa391\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '5a179071-4e22-4a84-aa4e-dbafcaffa391',\n",
       "                        [{\"mode\": \"markers\", \"name\": \"data\", \"text\": [], \"type\": \"scatter\", \"uid\": \"065d1b96-de97-48a3-8023-e0272c44951a\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [0.24923843719791383, 0.33082082917562416, 0.4338864581119427, 0.453339481417917, 0.46214081786104744, 0.3998070734028383, 0.40191055317088786, 0.41359458038845254, 0.42443502503868535, 0.42552761574430875]}],\n",
       "                        {},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5a179071-4e22-4a84-aa4e-dbafcaffa391');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graph import trace_values, plot\n",
    "x_vals = list(range(1, len(rfr.estimators_) + 1))\n",
    "trace = trace_values(x_vals, r2_scores)\n",
    "plot([trace])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, as we aggregate our trees, the performance of our model begins to improve.  This is the idea behind aggregating our trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Random Forest Top to Bottom](https://www.gormanalysis.com/blog/random-forest-from-top-to-bottom/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
