{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we saw that our random forests use multiple decision trees, referred to as estimators, to predict the target variable.  To create variation among the trees, the random forest trains each tree on a subset of the training data.  In this lesson we'll learn about bootstrapping with random forests, and how it can further increase the variation among our trees.  \n",
    "\n",
    "**Bootstrapping** means that when we sample a dataset, we sample our data with replacement.  The advantage of this is that it increases the differences of the subsamples we use to train our trees.  First, let's make sure we understand how bootstrapping works, and then we can understand how it increases the variance of our subsamples, and thus our trees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What it means to bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have observations one through thirteen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "one_to_thirteen = np.arange(1, 14)\n",
    "one_to_thirteen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were just to take a normal subsample of the data, then we would select five of the observations.  And each observation could only be selected once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8, 2, 7, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(21)\n",
    "np.random.choice(one_to_thirteen, 5, replace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above, each of our selected datapoints is unique as once they are selected, they are removed from the pool of available.  \n",
    "\n",
    "When we sample with replacement, or bootstrap, this isn't the case.  We select from the list of observations, but then place the datapoint back into the pool of data we can select from.  \n",
    "\n",
    "Let's see this in action.  We can bootstrap our array with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  9,  5,  1,  1,  9,  4, 13])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(21)\n",
    "np.random.choice(one_to_thirteen, 8, replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we see that we can select the same number multiple times, as even after selected once, it is still available to be selected again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Bootstrapping to Our Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand the operation behind bootstrapping let's see what happens if we apply bootstrapping to our training sets.  We'll continue to use our list of numbers, one through thirteen, to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_to_thirteen = np.arange(1, 14)\n",
    "x_train, x_test = train_test_split(one_to_thirteen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, mimicking the procedure of a random forest, let's begin by taking subsamples of our data, without replacement.  Let's say that we select sixty percent of our training set each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  6,  7,  9, 10],\n",
       "       [ 3,  4, 10, 11, 12, 13],\n",
       "       [ 3,  4,  6,  7, 11, 12],\n",
       "       [ 4,  7,  9, 10, 11, 12],\n",
       "       [ 3,  4,  6,  9, 10, 12]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(23)\n",
    "datasets = np.stack([np.random.choice(x_train, 6, replace = False) for num in range(0, 5)])\n",
    "datasets.sort(axis=1)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look closely at our datasets, notice that a couple of them are fairly similar.  The first and last rows share five of the six datapoints.  And the second and third rows share four of six datapoints.  This can be problematic because remember we want variation in our trees, as we want our trees to discover different patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what happens when we selecting subsamples of our training set with bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  3,  7, 11, 11, 13],\n",
       "       [ 6,  9, 10, 10, 11, 13],\n",
       "       [ 6,  7, 10, 12, 12, 13],\n",
       "       [ 4,  4,  6,  6,  7, 11],\n",
       "       [ 3,  9, 11, 12, 13, 13]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(23)\n",
    "datasets = np.stack([np.random.choice(x_train, 6, replace = True) for num in range(0, 5)])\n",
    "datasets.sort(axis=1)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that we get a lot more variation in our data.  With bootstrapping, we simply have a lot more variations in our data. And this increases the variations among our trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping in Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our random forest in sklearn, bootstrapping is the default behavior of a random forest.  If we wanted to turn bootstrapping off, we can pass through an argument of `bootstrap = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor(bootstrap = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we don't want to do that.  \n",
    "\n",
    "With the current default behavior, our random forest will sample with replacement before constructing each tree in the random forest.  This increases the variances of our trees.  And this is a good thing, because we will ultimately accomodate for that variance by aggregate our trees at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we saw how bootstrapping can increase the variation among our trees.  Bootstrapping means to sample a dataset with replacement.  As we saw this increases the variation among each sampled dataset, which leads to more variation among each tree that we train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Random Forest Top to Bottom](https://www.gormanalysis.com/blog/random-forest-from-top-to-bottom/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
