{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating Trees Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll see the benefits of aggregating trees in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, let's work with the diabetes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by loading the diabetes dataset from sklearn.  Assign `X` to our feature variables and `y` to the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "dataset = load_diabetes()\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# (442, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442,)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n",
    "# (442,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split our data into training, test and validation sets.\n",
    "\n",
    "Perform this by:\n",
    "1. Splitting the data into training and test sets\n",
    "2. Splitting the training set into training and validation sets\n",
    "\n",
    "* Use the `random_state=1` and `test_size=0.2` for both splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07453279,  0.05068012, -0.00943939,  0.01498661, -0.03734373,\n",
       "        -0.02166853, -0.01394774, -0.00259226, -0.03324879,  0.01134862]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1]\n",
    "# array([[-0.07453279,  0.05068012, -0.00943939,  0.01498661, -0.03734373,\n",
    "#         -0.02166853, -0.01394774, -0.00259226, -0.03324879,  0.01134862]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01991321,  0.05068012,  0.01427248,  0.0631868 ,  0.01494247,\n",
       "         0.02029337, -0.04708248,  0.03430886,  0.04666077,  0.09004865]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[:1]\n",
    "# array([[ 0.01991321,  0.05068012,  0.01427248,  0.0631868 ,  0.01494247,\n",
    "#         0.02029337, -0.04708248,  0.03430886,  0.04666077,  0.09004865]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04170844, -0.04464164, -0.03207344, -0.06190417,  0.07961226,\n",
       "         0.05098192,  0.05600338, -0.00997249,  0.04506617, -0.05906719]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]\n",
    "\n",
    "#array([[ 0.04170844, -0.04464164, -0.03207344, -0.06190417,  0.07961226,\n",
    "#         0.05098192,  0.05600338, -0.00997249,  0.04506617, -0.05906719]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll begin aggregating our trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by fitting multiple decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22211951488597947"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a list of five trees.  Fit each tree on the entire training set.  Set the random state on the `DecistionTreeRegressor` to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_trees = []\n",
    "for idx in range(0, 5):\n",
    "    dtr = DecisionTreeRegressor(random_state=1)\n",
    "    dtr.fit(X_train, y_train)\n",
    "    fitted_trees.append(dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11528633202604144,\n",
       " 0.11528633202604144,\n",
       " 0.11528633202604144,\n",
       " 0.11528633202604144,\n",
       " 0.11528633202604144]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tree.score(X_val, y_val) for tree in fitted_trees]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each tree performs the same, because each tree is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"304pt\" height=\"244pt\"\n",
       " viewBox=\"0.00 0.00 304.00 244.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 240)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-240 300,-240 300,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"201.2133,-236 94.7867,-236 94.7867,-172 201.2133,-172 201.2133,-236\"/>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">s5 &lt;= 0.022</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 5942.067</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 282</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 150.337</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"138.9473,-136 33.0527,-136 33.0527,-72 138.9473,-72 138.9473,-136\"/>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bmi &lt;= 0.006</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 3929.642</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 187</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 119.77</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M128.0415,-171.8089C122.6763,-163.1553 116.8035,-153.683 111.1937,-144.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"114.1652,-142.7855 105.9211,-136.1308 108.2159,-146.4741 114.1652,-142.7855\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.2118\" y=\"-156.2701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 356 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>356</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"263.2133,-136 156.7867,-136 156.7867,-72 263.2133,-72 263.2133,-136\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bp &lt;= 0.058</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 4443.976</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 95</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 210.505</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;356 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;356</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M167.9585,-171.8089C173.3237,-163.1553 179.1965,-153.683 184.8063,-144.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.7841,-146.4741 190.0789,-136.1308 181.8348,-142.7855 187.7841,-146.4741\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.7882\" y=\"-156.2701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"54,-36 0,-36 0,0 54,0 54,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M64.0306,-71.9768C57.8384,-62.9509 51.1718,-53.2335 45.2249,-44.5651\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"48.1053,-42.5768 39.562,-36.3108 42.3331,-46.5368 48.1053,-42.5768\"/>\n",
       "</g>\n",
       "<!-- 263 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>263</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"126,-36 72,-36 72,0 126,0 126,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;263 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;263</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M90.8407,-71.9768C92.1198,-63.515 93.4908,-54.4455 94.7369,-46.2023\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.198,-46.7216 96.2321,-36.3108 91.2767,-45.6753 98.198,-46.7216\"/>\n",
       "</g>\n",
       "<!-- 357 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>357</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"224,-36 170,-36 170,0 224,0 224,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 356&#45;&gt;357 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>356&#45;&gt;357</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M205.1593,-71.9768C203.8802,-63.515 202.5092,-54.4455 201.2631,-46.2023\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.7233,-45.6753 199.7679,-36.3108 197.802,-46.7216 204.7233,-45.6753\"/>\n",
       "</g>\n",
       "<!-- 492 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>492</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"296,-36 242,-36 242,0 296,0 296,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 356&#45;&gt;492 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>356&#45;&gt;492</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M231.9694,-71.9768C238.1616,-62.9509 244.8282,-53.2335 250.7751,-44.5651\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"253.6669,-46.5368 256.438,-36.3108 247.8947,-42.5768 253.6669,-46.5368\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a27f88278>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from IPython.display import SVG, display\n",
    "from graphviz import Source \n",
    "\n",
    "\n",
    "graph_1 = Source(tree.export_graphviz(fitted_trees[0], out_file=None,\n",
    "                                feature_names=dataset['feature_names'], max_depth = 1))\n",
    "\n",
    "graph_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"304pt\" height=\"244pt\"\n",
       " viewBox=\"0.00 0.00 304.00 244.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 240)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-240 300,-240 300,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"201.2133,-236 94.7867,-236 94.7867,-172 201.2133,-172 201.2133,-236\"/>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">s5 &lt;= 0.022</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 5942.067</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 282</text>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 150.337</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"138.9473,-136 33.0527,-136 33.0527,-72 138.9473,-72 138.9473,-136\"/>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bmi &lt;= 0.006</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 3929.642</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 187</text>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 119.77</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M128.0415,-171.8089C122.6763,-163.1553 116.8035,-153.683 111.1937,-144.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"114.1652,-142.7855 105.9211,-136.1308 108.2159,-146.4741 114.1652,-142.7855\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.2118\" y=\"-156.2701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 356 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>356</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"263.2133,-136 156.7867,-136 156.7867,-72 263.2133,-72 263.2133,-136\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bp &lt;= 0.058</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 4443.976</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 95</text>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 210.505</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;356 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;356</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M167.9585,-171.8089C173.3237,-163.1553 179.1965,-153.683 184.8063,-144.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.7841,-146.4741 190.0789,-136.1308 181.8348,-142.7855 187.7841,-146.4741\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.7882\" y=\"-156.2701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"54,-36 0,-36 0,0 54,0 54,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M64.0306,-71.9768C57.8384,-62.9509 51.1718,-53.2335 45.2249,-44.5651\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"48.1053,-42.5768 39.562,-36.3108 42.3331,-46.5368 48.1053,-42.5768\"/>\n",
       "</g>\n",
       "<!-- 263 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>263</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"126,-36 72,-36 72,0 126,0 126,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;263 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;263</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M90.8407,-71.9768C92.1198,-63.515 93.4908,-54.4455 94.7369,-46.2023\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.198,-46.7216 96.2321,-36.3108 91.2767,-45.6753 98.198,-46.7216\"/>\n",
       "</g>\n",
       "<!-- 357 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>357</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"224,-36 170,-36 170,0 224,0 224,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 356&#45;&gt;357 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>356&#45;&gt;357</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M205.1593,-71.9768C203.8802,-63.515 202.5092,-54.4455 201.2631,-46.2023\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.7233,-45.6753 199.7679,-36.3108 197.802,-46.7216 204.7233,-45.6753\"/>\n",
       "</g>\n",
       "<!-- 492 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>492</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"296,-36 242,-36 242,0 296,0 296,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n",
       "</g>\n",
       "<!-- 356&#45;&gt;492 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>356&#45;&gt;492</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M231.9694,-71.9768C238.1616,-62.9509 244.8282,-53.2335 250.7751,-44.5651\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"253.6669,-46.5368 256.438,-36.3108 247.8947,-42.5768 253.6669,-46.5368\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a27fb37b8>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from IPython.display import SVG, display\n",
    "from graphviz import Source \n",
    "\n",
    "\n",
    "graph_1 = Source(tree.export_graphviz(fitted_trees[1], out_file=None,\n",
    "                                feature_names=dataset['feature_names'], max_depth = 1))\n",
    "\n",
    "graph_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Subsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, next, let's use subsampling to get a different set of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With numpy we cannot directly subsample from the array.  But we can subsample from our training data by first selecting a set of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 10)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(.8*len(X_train))\n",
    "# 225\n",
    "np.random.seed(1)\n",
    "\n",
    "selected_idx = np.random.choice(len(X_train), 225)\n",
    "selected_idx[:3]\n",
    "\n",
    "# array([ 37, 235,  72])\n",
    "selected_X_train = X_train[selected_idx]\n",
    "selected_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the above code randomly selects eighty percent of the data.  Use this code to create ten additional trees, each trained on a random subset of 80 percent of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_trees = []\n",
    "for idx in range(0, 10):\n",
    "    selected_idx = np.random.choice(len(X_train), int(.8*len(X_train)))\n",
    "    selected_X_train = X_train[selected_idx]\n",
    "    selected_y_train = y_train[selected_idx]\n",
    "    dtr = DecisionTreeRegressor(random_state=1)\n",
    "    dtr.fit(selected_X_train, selected_y_train)\n",
    "    subsample_trees.append(dtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see a range of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24923843719791383,\n",
       " 0.03647017991735613,\n",
       " 0.1325589994677966,\n",
       " 0.07175112929272864,\n",
       " -0.03401705945212541,\n",
       " -0.4232647229908093,\n",
       " -0.10466898863321772,\n",
       " 0.13665209025236702,\n",
       " 0.11395563834822497,\n",
       " -0.01769080946109436]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_subsample_scores = [tree.score(X_val, y_val) for tree in subsample_trees]\n",
    "tree_subsample_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, individually, our trees don't perform any better than they did originally.  In many cases, the trees perform worse.  But the key component of a random forest is that our trees are different.  And that aggregating these differences will produce a more accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's use our first tree to make predictions on our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tree = subsample_trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = first_tree.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([268.,  48., 221., 197.,  63.,  48.,  61., 233., 131., 248., 257.,\n",
       "       111.,  99.,  47., 128., 175., 270., 210., 143., 237.,  72., 104.,\n",
       "       197., 101., 221., 175., 160., 185., 206., 116.,  84.,  75., 248.,\n",
       "       175.,  95., 232., 134.,  70.,  73., 259.,  45., 198.,  83.,  71.,\n",
       "       128., 232.,  72., 110., 150.,  73., 206., 185.,  44., 248., 235.,\n",
       "       143.,  53., 122.,  86.,  70., 116., 107., 113.,  71., 151., 134.,\n",
       "       192.,  65.,  48.,  84., 197.])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here, we see the predictions that our tree makes for each observation.  \n",
    "\n",
    "Now for a random forest of three trees, we should have three trees make predictions, and then get the mean prediction for each observation across these trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Have each tree make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now let's first create a matrix where each row is a set of predictions for each tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use `vstack` along with list comprehension, to place each set of tree predictions into a separate row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tree_predictions = np.vstack([ tree.predict(X_val) for tree in subsample_trees])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 71)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_predictions[:3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a matrix where each row is a separate set of predictions.  The next step is to begin to aggregate these predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Aggregate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tree prediction matrix has a separate row for each set of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[268.,  48., 221., 197.,  63.,  48.,  61., 233., 131., 248., 257.,\n",
       "        111.,  99.,  47., 128., 175., 270., 210., 143., 237.,  72., 104.,\n",
       "        197., 101., 221., 175., 160., 185., 206., 116.,  84.,  75., 248.,\n",
       "        175.,  95., 232., 134.,  70.,  73., 259.,  45., 198.,  83.,  71.,\n",
       "        128., 232.,  72., 110., 150.,  73., 206., 185.,  44., 248., 235.,\n",
       "        143.,  53., 122.,  86.,  70., 116., 107., 113.,  71., 151., 134.,\n",
       "        192.,  65.,  48.,  84., 197.],\n",
       "       [150.,  77., 221., 202., 158., 153.,  63., 281., 259., 118., 295.,\n",
       "         59.,  65.,  64., 150., 140., 246., 277.,  67.,  70., 141.,  72.,\n",
       "         96.,  65., 220., 277.,  87., 161., 146., 143.,  74.,  64., 202.,\n",
       "        277., 103., 259., 141., 281., 197., 279., 101., 236.,  49., 101.,\n",
       "        192., 265., 118.,  70.,  87., 190., 249., 249., 153., 202., 220.,\n",
       "         61., 129.,  67.,  87., 244., 104., 131., 145.,  54., 225.,  83.,\n",
       "        128.,  42.,  52.,  70., 202.]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_predictions[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to take the mean prediction for each observation, across all of our rows.  If we just use `np.mean` numpy will calculate the mean score across all of our predictions.  But this isn't what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.25774647887323"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tree_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we want the mean prediction for each observation.  Or the mean across our rows.  To do so, use `np.mean` with `axis` set to `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_predictions = np.mean(tree_predictions, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([238.8,  68.5, 186.8, 161.1,  96.6,  83.9,  78.3, 259.6, 183.5,\n",
       "       149.2, 265.3,  83.3,  76.7,  59.8, 192.5, 118.2, 250.6, 201.5,\n",
       "       218.8, 167.3, 108. ,  89. , 137.1, 118.2, 218.6, 201.4, 109.3,\n",
       "       142.4, 155.9,  91.5, 117.4,  68.3, 205.5, 217.4, 156. , 233.9,\n",
       "       175.9, 209.3, 135.7, 268. , 118.3, 241.7,  83.6,  89.4, 197.6,\n",
       "       220.3,  85.8, 179.7, 158.4, 158.7, 143.9, 152.9,  73.7, 188.6,\n",
       "       255.3,  90.2,  60.5, 211.9, 160.4, 191.8,  81.1, 164.9, 107.7,\n",
       "        76.2, 158.2, 155.3, 181. ,  60.9,  71.7, 108.3, 141.2])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71,)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we still have a prediction for each of our datapoints, but now they are mean of the predictions of our trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how this performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate the $r^2$ for our combined trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42552761574430875"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_val, aggregated_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our score dramatically increased by aggregating the trees.  In fact, we performed better than with any individual tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24923843719791383,\n",
       " 0.03647017991735613,\n",
       " 0.1325589994677966,\n",
       " 0.07175112929272864,\n",
       " -0.03401705945212541,\n",
       " -0.4232647229908093,\n",
       " -0.10466898863321772,\n",
       " 0.13665209025236702,\n",
       " 0.11395563834822497,\n",
       " -0.01769080946109436]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_subsample_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, finally, we'll provide the code to show how our predictions improve as we add each additional estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_scores = [r2_score(y_val, np.mean(tree_predictions[:i + 1], axis = 0)) for i in range(0, len(subsample_trees)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "markers",
         "name": "data",
         "text": [],
         "type": "scatter",
         "uid": "065d1b96-de97-48a3-8023-e0272c44951a",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          0.24923843719791383,
          0.33082082917562416,
          0.4338864581119427,
          0.453339481417917,
          0.46214081786104744,
          0.3998070734028383,
          0.40191055317088786,
          0.41359458038845254,
          0.42443502503868535,
          0.42552761574430875
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "xaxis": {
         "autorange": true,
         "range": [
          0.4319912948857455,
          10.568008705114254
         ],
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          0.233643676830869,
          0.47773557822809226
         ],
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"5a179071-4e22-4a84-aa4e-dbafcaffa391\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"5a179071-4e22-4a84-aa4e-dbafcaffa391\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '5a179071-4e22-4a84-aa4e-dbafcaffa391',\n",
       "                        [{\"mode\": \"markers\", \"name\": \"data\", \"text\": [], \"type\": \"scatter\", \"uid\": \"065d1b96-de97-48a3-8023-e0272c44951a\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [0.24923843719791383, 0.33082082917562416, 0.4338864581119427, 0.453339481417917, 0.46214081786104744, 0.3998070734028383, 0.40191055317088786, 0.41359458038845254, 0.42443502503868535, 0.42552761574430875]}],\n",
       "                        {},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5a179071-4e22-4a84-aa4e-dbafcaffa391');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graph import trace_values, plot\n",
    "x_vals = list(range(1, len(rfr.estimators_) + 1))\n",
    "trace = trace_values(x_vals, r2_scores)\n",
    "plot([trace])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, as we aggregate our trees, the performance of our model begins to improve.  This is the idea behind aggregating our trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Random Forest Top to Bottom](https://www.gormanalysis.com/blog/random-forest-from-top-to-bottom/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
